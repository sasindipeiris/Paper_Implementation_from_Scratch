{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "urDFnZE8Vh5n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['mobilenetv4_conv_small', 'mobilenetv4_conv_medium','mobilenetv4_conv_large','mobilenetv4_hybrid_medium','mobilenetv4_hybrid_large']"
      ],
      "metadata": {
        "id": "m3CQc31sVx3q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The make_divisble function (note: it should be make_divisible, likely a typo) is a utility often used in deep learning (e.g., MobileNet, EfficientNet) to ensure that a given value (typically the number of channels or filters) is divisible by a specific number (e.g., 8 or 16). This helps maintain alignment with hardware requirements for memory and computational efficiency."
      ],
      "metadata": {
        "id": "dO02oj7KXazI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_divisible(value,divisor,min_value=None,round_down_protect=True):\n",
        "  if min_value is None:\n",
        "    min_value=divisor\n",
        "  new_value=max(min_value,int(value +divisor/2)//divisor*divisor) #This line rounds value to the nearest multiple of divisor, but ensures it's at least min_value.\n",
        "  if round_down_protect and new_value < 0.9*value: #If new_value is less than 90% of the original value, it increments it by one more divisor to avoid excessive downscaling.\n",
        "    new_value+=divisor\n",
        "  return new_value\n"
      ],
      "metadata": {
        "id": "e-JOKge7WXCz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Term                     | Meaning                                                            |\n",
        "| ------------------------ | ------------------------------------------------------------------ |\n",
        "| `inplace=True`           | Modify the input tensor directly (save memory, faster, but risky)  |\n",
        "| `(kernel_size - 1) // 2` | Padding to preserve input size during convolution (\"same padding\") |\n"
      ],
      "metadata": {
        "id": "oFsy76FuY63p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBN(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,kernel_size,stride=1):\n",
        "    super(ConvBN,self).__init__()\n",
        "    self.block=nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size,stride,(kernel_size -1)//2,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.block(x)"
      ],
      "metadata": {
        "id": "g1BrKcLLXyHc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Parameter                | Type    | Description                                                                                                                                    |\n",
        "| ------------------------ | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| `self`                   | object  | Reference to the class instance (standard in Python class methods).                                                                            |\n",
        "| `in_channels`            | `int`   | Number of input channels to the block.                                                                                                         |\n",
        "| `out_channels`           | `int`   | Number of output channels from the block.                                                                                                      |\n",
        "| `expand_ratio`           | `float` | Expansion factor for hidden (intermediate) channels, e.g., in MobileNet blocks. Determines how much to increase channels in expansion phase.   |\n",
        "| `start_dw_kernel_size`   | `int`   | Kernel size for the **initial depthwise convolution**. Helps control local receptive field at the beginning of the block.                      |\n",
        "| `middle_dw_kernel_size`  | `int`   | Kernel size for the **middle depthwise convolution**, possibly the main feature extraction part of the block.                                  |\n",
        "| `stride`                 | `int`   | Stride used in depthwise convolution, controls spatial downsampling (1 = no downsampling, 2 = halve spatial size).                             |\n",
        "| `middle_dw_downsample`   | `bool`  | If `True`, the middle depthwise conv uses `stride > 1` for downsampling; if `False`, no downsampling in the middle.                            |\n",
        "| `use_layer_scale`        | `bool`  | If `True`, applies a **learnable scaling factor** (Layer Scale) to the block's output. Often used to stabilize training in very deep networks. |\n",
        "| `layer_scale_init_value` | `float` | Initial value for the layer scale parameter (e.g., `1e-5` is a small initial scaling). Used only if `use_layer_scale` is `True`.               |\n"
      ],
      "metadata": {
        "id": "ZlvdR5g5aZ6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Code Line                                                     | Purpose                                                                                                                                                                              |\n",
        "| ------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
        "| `if use_layer_scale:`                                         | Conditional check to determine whether to apply **Layer Scale**.                                                                                                                     |\n",
        "| `self.gamma = nn.Parameter(...)`                              | Creates a learnable parameter `gamma`, a 1D tensor of shape `(out_channels,)`, initialized with `layer_scale_init_value`. This parameter will later scale the block’s output.        |\n",
        "| `torch.ones((out_channels))`                                  | Initializes the scale as a tensor of ones — one scale per output channel.                                                                                                            |\n",
        "| `nn.Parameter(..., requires_grad=True)`                       | Ensures that `gamma` is a learnable parameter, updated via backpropagation.                                                                                                          |\n",
        "| `self.use_layer_scale = use_layer_scale`                      | Stores the flag so that it can be used in `forward()` or elsewhere in the module.                                                                                                    |\n",
        "| `self.identity = stride == 1 and in_channels == out_channels` | Indicates whether the block can use a **residual/identity connection** (i.e., skip connection), which is only valid if the input and output shapes match spatially and channel-wise. |\n"
      ],
      "metadata": {
        "id": "S_H7dxvFeCJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UniversalInvertedBottleneck(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               out_channels,\n",
        "               expand_ratio,\n",
        "               start_dw_kernel_size,\n",
        "               middle_dw_kernel_size,\n",
        "               stride,\n",
        "               middle_dw_downsample: bool = True,\n",
        "               use_layer_scale:bool=False,\n",
        "               layer_scale_init_value: float = 1e-5):\n",
        "    super(UniversalInvertedBottleneck,self).__init__()\n",
        "    self.start_dw_kernel_size=start_dw_kernel_size\n",
        "    self.middle_dw_kernel_size=middle_dw_kernel_size\n",
        "\n",
        "    if start_dw_kernel_size:\n",
        "      self.start_dw_conv = nn.Conv2d(in_channels,in_channels,start_dw_kernel_size,stride if not middle_dw_downsample else 1,(start_dw_kernel_size-1)//2,groups=in_channels,bias=False)\n",
        "      self.start_dw_norm=nn.BatchNorm2d(in_channels)\n",
        "\n",
        "\n",
        "    expand_channels=make_divisible(in_channels*expand_ratio,8)\n",
        "    self.expand_conv=nn.Conv2d(in_channels,expand_channels,1,1,bias=False)\n",
        "    self.expand_norm=nn.BatchNorm2d(expand_channels)\n",
        "    self.expand_act=nn.ReLU(inplace=True)\n",
        "\n",
        "    if middle_dw_kernel_size:\n",
        "      self.middle_dw_conv=nn.Conv2d(expand_channels,expand_channels,middle_dw_kernel_size,stride if middle_dw_downsample else 1,(middle_dw_kernel_size -1)//2,groups=expand_channels,bias=False)\n",
        "      self.middle_dw_norm=nn.BatchNorm2d(expand_channels)\n",
        "      self.middle_dw_act=nn.ReLU(inplace=True)\n",
        "\n",
        "    self.proj_conv=nn.Conv2d(expand_channels,out_channels,1,1,bias=False)\n",
        "    self.proj_norm=nn.BtachNorm2d(out_channels)\n",
        "\n",
        "    if use_layer_scale:\n",
        "      self.gamma = nn.Parameter(layer_scale_init_value*torch.ones((out_channels)),requires_grad=True)\n",
        "\n",
        "    self.use_layer_scale=use_layer_scale\n",
        "    self.identity=stride == 1 and in_channels == out_channels\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "\n",
        "    if self.start_dw_kernel_size:\n",
        "      x=self.start_dw_conv(x)\n",
        "      x=self.start_dw_norm(x)\n",
        "\n",
        "    x=self.expand_conv(x)\n",
        "    x=self.expand_norm(x)\n",
        "    x=self.expand_act(x)\n",
        "\n",
        "    if self.middle_dw_kernel_size:\n",
        "      x=self.middle_dw_conv(x)\n",
        "      x=self.middle_dw_norm(x)\n",
        "      x=self.middle_dw_act(x)\n",
        "\n",
        "    x=self.proj_conv(x)\n",
        "    x=self.proj_norm(x)\n",
        "\n",
        "    if self.use_layer_scale_scale:\n",
        "      x=self.gamma*x\n",
        "\n",
        "    return x + shortcut if self.identity else x\n",
        "\n"
      ],
      "metadata": {
        "id": "hgu-6361Y8Uy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Layer/Variable               | Description                                                                                                                         |\n",
        "| ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| `self.avgpool`               | `nn.AdaptiveAvgPool2d((1, 1))` — Reduces each feature map to **1×1** (global average pooling), output shape becomes `(B, C, 1, 1)`. |\n",
        "| `hidden_channels`            | Set to `1280` — used as the number of channels after the final pointwise conv layer. Common in lightweight CNNs.                    |\n",
        "| `self.conv`                  | `ConvBN(c, 1280, 1)` — A `1×1` convolution that expands from `c` (last `out_channels`) to 1280. Applies batch norm + activation.    |\n",
        "| `self.classifier`            | `nn.Linear(1280, num_classes)` — Final fully connected layer mapping from feature vector to output logits.                          |\n",
        "| `self._initialize_weights()` | Custom method to initialize model weights (usually uses Xavier/He/Kaiming init).                                                    |\n"
      ],
      "metadata": {
        "id": "UaBcghjyhxVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Component     | Purpose                              |\n",
        "| ------------- | ------------------------------------ |\n",
        "| `x.size(0)`   | Keeps the **batch size** unchanged   |\n",
        "| `-1`          | Flattens all remaining dimensions    |\n",
        "| `x.view(...)` | Reshapes tensor without copying data |\n"
      ],
      "metadata": {
        "id": "z4DSd0Fliudg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Module Type      | Initialization Method                   | Reason                                                  |\n",
        "| ---------------- | --------------------------------------- | ------------------------------------------------------- |\n",
        "| `nn.Conv2d`      | He (Kaiming) Normal with std `√(2 / n)` | Suitable for ReLU activation (helps maintain variance). |\n",
        "|                  | Bias: zero                              | Standard to avoid early biasing.                        |\n",
        "| `nn.BatchNorm2d` | Weights = 1, Biases = 0                 | Keeps initial feature scaling neutral.                  |\n",
        "| `nn.Linear`      | Normal(0, 0.01) for weights             | Standard small weight init for fully connected layers.  |\n",
        "|                  | Bias = 0                                | Keeps outputs unbiased at start.                        |\n"
      ],
      "metadata": {
        "id": "Z5vFHAPEkb-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileNetV4(nn.Module):\n",
        "  def __init__(self,block_specs,num_classes=1000):\n",
        "    super(MobileNetV4,self).__init__()\n",
        "\n",
        "    c=3\n",
        "    layers=[]\n",
        "    for block_type,*block_cfg in block_specs:\n",
        "      if block_type =='conv_bn':\n",
        "        block=ConvBN\n",
        "        k,s,f=block_cfg\n",
        "        layers.append(block(c,f,k,s))\n",
        "      elif block_type =='uib':\n",
        "        block=UniversalInvertedBlock\n",
        "        start_k,middle_k,s,f,e=block_cfg\n",
        "        layers.append(block(c,f,e,start_k,middle_k,s))\n",
        "      else:\n",
        "        raise NotImplementedError\n",
        "      c=f\n",
        "\n",
        "      self.features=nn.Sequential(*layers)\n",
        "      #building last several layers\n",
        "      self.avgpool=nn.AdaptiveAvgPool2d((1,1))\n",
        "      hidden_channels=1280\n",
        "      self.conv=ConvBN(c,hidden_channels,1)\n",
        "      self.classifier=nn.Linear(hidden_channels,num_classes)\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.features(x)\n",
        "    x=self.avgpool(x)\n",
        "    x=self.conv(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x=self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m,nn.Conv2d):\n",
        "        n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n",
        "        m.weight.data.normal_(0,math,sqrt(2./n))\n",
        "        if m.bias is not None:\n",
        "          m.bias.data.zero()\n",
        "      elif isinstance(m,nn.BatchNorm2d):\n",
        "        m.weight.data.fill_(1)\n",
        "        m.bias.data.zero_()\n",
        "      elif isinstance(m,nn.Linear):\n",
        "        m.weight.data.normal_(0,0.01)\n",
        "        m.bias.data.zero_()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xAkaT0HWfQeI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenetv4_conv_small(**kwargs):\n",
        "  block_specs=[\n",
        "        # conv_bn, kernel_size, stride, out_channels\n",
        "        # uib, start_dw_kernel_size, middle_dw_kernel_size, stride, out_channels, expand_ratio\n",
        "        # 112px\n",
        "        ('conv_bn', 3, 2, 32),\n",
        "        # 56px\n",
        "        ('conv_bn', 3, 2, 32),\n",
        "        ('conv_bn', 1, 1, 32),\n",
        "        # 28px\n",
        "        ('conv_bn', 3, 2, 96),\n",
        "        ('conv_bn', 1, 1, 64),\n",
        "        # 14px\n",
        "        ('uib', 5, 5, 2, 96, 3.0),  # ExtraDW\n",
        "        ('uib', 0, 3, 1, 96, 2.0),  # IB\n",
        "        ('uib', 0, 3, 1, 96, 2.0),  # IB\n",
        "        ('uib', 0, 3, 1, 96, 2.0),  # IB\n",
        "        ('uib', 0, 3, 1, 96, 2.0),  # IB\n",
        "        ('uib', 3, 0, 1, 96, 4.0),  # ConvNext\n",
        "        # 7px\n",
        "        ('uib', 3, 3, 2, 128, 6.0),  # ExtraDW\n",
        "        ('uib', 5, 5, 1, 128, 4.0),  # ExtraDW\n",
        "        ('uib', 0, 5, 1, 128, 4.0),  # IB\n",
        "        ('uib', 0, 5, 1, 128, 3.0),  # IB\n",
        "        ('uib', 0, 3, 1, 128, 4.0),  # IB\n",
        "        ('uib', 0, 3, 1, 128, 4.0),  # IB\n",
        "        ('conv_bn', 1, 1, 960),  # Conv\n",
        "    ]\n",
        "  return MobileNetV4(block_specs, **kwargs)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "JCbaxbNhkfnU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenetv4_conv_medium(*kwargs):\n",
        "  block_specs = [\n",
        "        ('conv_bn', 3, 2, 32),\n",
        "        ('conv_bn', 3, 2, 128),\n",
        "        ('conv_bn', 1, 1, 48),\n",
        "        # 3rd stage\n",
        "        ('uib', 3, 5, 2, 80, 4.0),\n",
        "        ('uib', 3, 3, 1, 80, 2.0),\n",
        "        # 4th stage\n",
        "        ('uib', 3, 5, 2, 160, 6.0),\n",
        "        ('uib', 3, 3, 1, 160, 4.0),\n",
        "        ('uib', 3, 3, 1, 160, 4.0),\n",
        "        ('uib', 3, 5, 1, 160, 4.0),\n",
        "        ('uib', 3, 3, 1, 160, 4.0),\n",
        "        ('uib', 3, 0, 1, 160, 4.0),\n",
        "        ('uib', 0, 0, 1, 160, 2.0),\n",
        "        ('uib', 3, 0, 1, 160, 4.0),\n",
        "        # 5th stage\n",
        "        ('uib', 5, 5, 2, 256, 6.0),\n",
        "        ('uib', 5, 5, 1, 256, 4.0),\n",
        "        ('uib', 3, 5, 1, 256, 4.0),\n",
        "        ('uib', 3, 5, 1, 256, 4.0),\n",
        "        ('uib', 0, 0, 1, 256, 4.0),\n",
        "        ('uib', 3, 0, 1, 256, 4.0),\n",
        "        ('uib', 3, 5, 1, 256, 2.0),\n",
        "        ('uib', 5, 5, 1, 256, 4.0),\n",
        "        ('uib', 0, 0, 1, 256, 4.0),\n",
        "        ('uib', 0, 0, 1, 256, 4.0),\n",
        "        ('uib', 5, 0, 1, 256, 2.0),\n",
        "        # FC layers\n",
        "        ('conv_bn',1,1960),\n",
        "  ]\n",
        "  return MobileNetV4(block_specs,**kwargs)\n",
        "\n"
      ],
      "metadata": {
        "id": "Fa148V-Vmbem"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenetv4_conv_large(**kwargs):\n",
        "  block_specs = [\n",
        "        ('conv_bn', 3, 2, 24),\n",
        "        ('conv_bn', 3, 2, 96),\n",
        "        ('conv_bn', 1, 1, 48),\n",
        "        ('uib', 3, 5, 2, 96, 4.0),\n",
        "        ('uib', 3, 3, 1, 96, 4.0),\n",
        "        ('uib', 3, 5, 2, 192, 4.0),\n",
        "        ('uib', 3, 3, 1, 192, 4.0),\n",
        "        ('uib', 3, 3, 1, 192, 4.0),\n",
        "        ('uib', 3, 3, 1, 192, 4.0),\n",
        "        ('uib', 3, 5, 1, 192, 4.0),\n",
        "        ('uib', 5, 3, 1, 192, 4.0),\n",
        "        ('uib', 5, 3, 1, 192, 4.0),\n",
        "        ('uib', 5, 3, 1, 192, 4.0),\n",
        "        ('uib', 5, 3, 1, 192, 4.0),\n",
        "        ('uib', 5, 3, 1, 192, 4.0),\n",
        "        ('uib', 3, 0, 1, 192, 4.0),\n",
        "        ('uib', 5, 5, 2, 512, 4.0),\n",
        "        ('uib', 5, 5, 1, 512, 4.0),\n",
        "        ('uib', 5, 5, 1, 512, 4.0),\n",
        "        ('uib', 5, 5, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('uib', 5, 3, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('uib', 5, 3, 1, 512, 4.0),\n",
        "        ('uib', 5, 5, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('uib', 5, 0, 1, 512, 4.0),\n",
        "        ('conv_bn', 1, 1, 960),\n",
        "    ]\n",
        "\n",
        "  return MobileNetV4(block_specs, **kwargs)\n"
      ],
      "metadata": {
        "id": "RiB47OCynAbO"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}